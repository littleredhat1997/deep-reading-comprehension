{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考 https://keras-cn-docs.readthedocs.io/zh_CN/latest/blog/word_embedding/\n",
    "\n",
    "### 什么是词向量?\n",
    "”词向量”（词嵌入）是将一类将词的语义映射到向量空间中去的自然语言处理技术。即将一个词用特定的向量来表示，向量之间的距离（例如，任意两个向量之间的L2范式距离或更常用的余弦距离）一定程度上表征了的词之间的语义关系。由这些向量形成的几何空间被称为一个嵌入空间。\n",
    "\n",
    "例如，“椰子”和“北极熊”是语义上完全不同的词，所以它们的词向量在一个合理的嵌入空间的距离将会非常遥远。但“厨房”和“晚餐”是相关的话，所以它们的词向量之间的距离会相对小。\n",
    "\n",
    "理想的情况下，在一个良好的嵌入空间里，从“厨房”向量到“晚餐”向量的“路径”向量会精确地捕捉这两个概念之间的语义关系。在这种情况下，“路径”向量表示的是“发生的地点”，所以你会期望“厨房”向量 - “晚餐\"向量（两个词向量的差异）捕捉到“发生的地点”这样的语义关系。基本上，我们应该有向量等式：晚餐 + 发生的地点 = 厨房（至少接近）。如果真的是这样的话，那么我们可以使用这样的关系向量来回答某些问题。例如，应用这种语义关系到一个新的向量，比如“工作”，我们应该得到一个有意义的等式，工作+ 发生的地点 = 办公室，来回答“工作发生在哪里？”。\n",
    "\n",
    "词向量通过降维技术表征文本数据集中的词的共现信息。方法包括神经网络(“Word2vec”技术)，或矩阵分解。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['小时候 ， 乡愁 是 一枚 小小的 邮票 ， 我 在 这头 ， 母亲 在 那头 。 长大 后 ， 乡愁 是 一张 窄窄的 船票 ， 我 在 这头 ， 新娘 在 那头 。 后来 啊 ， 乡愁 是 一方 矮矮的 坟墓 ， 我 在 外头 ， 母亲 在 里头 。 而 现在 ， 乡愁 是 一湾 浅浅的 海峡 ， 我 在 这头 ， 大陆 在 那头 。']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jieba\n",
    "\n",
    "text = '小时候，乡愁是一枚小小的邮票，我在这头，母亲在那头。长大后，乡愁是一张窄窄的船票，我在这头，新娘在那头。后来啊，乡愁是一方矮矮的坟墓，我在外头，母亲在里头。而现在，乡愁是一湾浅浅的海峡，我在这头，大陆在那头。'\n",
    "texts = [' '.join(jieba.cut(text))]\n",
    "texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'。': 6,\n",
       " '一张': 16,\n",
       " '一方': 22,\n",
       " '一枚': 11,\n",
       " '一湾': 29,\n",
       " '乡愁': 3,\n",
       " '后': 15,\n",
       " '后来': 20,\n",
       " '啊': 21,\n",
       " '在': 2,\n",
       " '坟墓': 24,\n",
       " '外头': 25,\n",
       " '大陆': 32,\n",
       " '小小的': 12,\n",
       " '小时候': 10,\n",
       " '我': 5,\n",
       " '新娘': 19,\n",
       " '是': 4,\n",
       " '母亲': 9,\n",
       " '浅浅的': 30,\n",
       " '海峡': 31,\n",
       " '现在': 28,\n",
       " '矮矮的': 23,\n",
       " '窄窄的': 17,\n",
       " '而': 27,\n",
       " '船票': 18,\n",
       " '这头': 7,\n",
       " '那头': 8,\n",
       " '邮票': 13,\n",
       " '里头': 26,\n",
       " '长大': 14,\n",
       " '，': 1}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "MAX_NB_WORDS = 50\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, lower=False)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 9], [23, 24]]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = '乡愁 母亲'\n",
    "text2 = '矮矮的 坟墓'\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences([text1, text2])\n",
    "sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  0,  0,  0,  0,  3,  9],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0, 23, 24]], dtype=int32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 10\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "经过上面的过程 tokenizer保存了语料中出现过的词的编号映射。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
